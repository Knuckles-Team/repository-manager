---
services:
  repository-manager-mcp:
    image: docker.io/knucklessg1/repository-manager:latest
    # build: . # Debug
    container_name: repository-manager-mcp
    hostname: repository-manager-mcp
    volumes:
      - ./mcp/development:/development
    command: ["repository-manager-mcp"]
    extra_hosts:
      - "host.docker.internal:host-gateway"
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    restart: always
    environment:
      - "HOST=0.0.0.0"
      - "PORT=8017"
      - "TRANSPORT=streamable-http"
      - "REPOSITORY_MANAGER_DIRECTORY=/development"
      - "REPOSITORY_MANAGER_THREADS=12"
      - "REPOSITORY_MANAGER_DEFAULT_BRANCH=True"
    ports:
      - "8017:8017"

  repository-manager-agent:
    image: docker.io/knucklessg1/repository-manager:latest
    # build: . # Debug
    container_name: repository-manager-agent
    hostname: repository-manager-agent
    command: ["repository-manager-agent"]
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - repository-manager-mcp
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    restart: always
    environment:
      - "HOST=0.0.0.0"
      - "PORT=9017"
      # - "MCP_CONFIG=./repository_manager/mcp_config.json" # Optionally specify your own file - Default will use MCP_URL in the pre-packaged mcp_config.json
      - "MCP_URL=http://repository-manager-mcp:8017/mcp"
      - "PROVIDER=openai"
      - "OPENAI_BASE_URL=http://localhost:1234/v1"
      - "OPENAI_API_KEY=llama"
      - "MODEL_ID=qwen/qwen3-8b"
      - "DEBUG=False"
      - "ENABLE_WEB_UI=True"
    ports:
      - "9017:9017"
